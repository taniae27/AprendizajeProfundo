{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taniae27/AprendizajeProfundo/blob/main/Tarea_1_Retropropagaci%C3%B3n_en_red_densa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04e2110c",
      "metadata": {
        "id": "04e2110c"
      },
      "source": [
        "# 2. Retropropagación en red densa"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afd26f33",
      "metadata": {
        "id": "afd26f33"
      },
      "source": [
        "Programa el algoritmo de retropropagación usando NumPy para una tarea de clasificación binaria presuponiendo una red densa con dos capas ocultas. Esta red tiene una función de activación logística en todas sus neuronas y se entrena minimizando la función de pérdida de entropía cruzada\n",
        "binaria. Describe las fórmulas y reglas de actualización de los pesos y sesgos de cada capa y entrena\n",
        "y evalúa la red en algún conjunto de datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "da5857f5",
      "metadata": {
        "id": "da5857f5"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "087d8e05",
      "metadata": {
        "id": "087d8e05"
      },
      "source": [
        "Nuestra red neuronal densa está compuesta por una capa de 2 entradas ($x_1$ y $x_2$), una capa oculta con 10 neuronas con función de activación sigmoide y una capa de salida con una sola neurona con función de activación sigmoide. Esta función de activación se define como:\n",
        "\n",
        "$$\n",
        "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c8278064",
      "metadata": {
        "id": "c8278064"
      },
      "outputs": [],
      "source": [
        "def sigmoide(z):\n",
        "    return 1 / (1 + np.exp(-z))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f47026f0",
      "metadata": {
        "id": "f47026f0"
      },
      "source": [
        "La función sigmoide tiene una derivada que está expresada en términos de la misma función, esto es, \n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\sigma (z)}{\\partial z} = \\sigma(z) (1 - \\sigma(z))\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6fa070d3",
      "metadata": {
        "id": "6fa070d3"
      },
      "outputs": [],
      "source": [
        "def derivada_sigmoide(x):\n",
        "    return np.multiply(sigmoide(x), (1.0 - sigmoide(x)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58e76f49",
      "metadata": {
        "id": "58e76f49"
      },
      "source": [
        "Usaremos la función de pérdida de entropía cruzada binaria:\n",
        "\n",
        "$$\n",
        "ECB(\\mathbf{y}, \\mathbf{\\hat{y}})  = -\\sum_{i=1}^N \\left[ y^{(i)} \\log \\hat{y}^{(i)} + (1 - y^{(i)}) \\log (1 - \\hat{y}^{(i)}) \\right]\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f0c54c84",
      "metadata": {
        "id": "f0c54c84"
      },
      "outputs": [],
      "source": [
        "def ECB(y, p):\n",
        "    p[p == 0] = np.nextafter(0., 1.)\n",
        "    p[p == 1] = np.nextafter(1., 0.)\n",
        "    return -(np.log(p[y == 1]).sum() + np.log(1 - p[y == 0]).sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c636c8d",
      "metadata": {
        "id": "7c636c8d"
      },
      "source": [
        "Posteriormente calcularemos la exactitud para medir el rendimiento del modelo aprendido por la red neuronal densa:\n",
        "\n",
        "$$\n",
        "exactitud = \\frac{correctos}{total}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "29848177",
      "metadata": {
        "id": "29848177"
      },
      "outputs": [],
      "source": [
        "def exactitud(y, y_predicha):\n",
        "    return (y == y_predicha).mean() * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96a3e3c6",
      "metadata": {
        "id": "96a3e3c6"
      },
      "source": [
        "Ahora, definimos la función que propaga hacia adelante una entrada $\\mathbf{x}^{i}$. Como la red está compuesta de 3 capas densas (2 ocultas y 1 de salida), tenemos 3 matrices de pesos con sus correspondientes vectores de sesgos $\\{\\mathbf{W}^{\\{1\\}}, \\mathbf{b}^{\\{1\\}}\\}$ , $\\{\\mathbf{W}^{\\{2\\}}, \\mathbf{b}^{\\{2\\}}\\}$ y $\\{\\mathbf{W}^{\\{3\\}}, \\mathbf{b}^{\\{3\\}}\\}$ de las capas ocultas y la capa de salida respectivamente. Así, podemos llevar a cabo la propagación hacia adelante en esta red de la siguiente manera:\n",
        "\n",
        "$$\n",
        "\t\\begin{split}\n",
        "\t\t\t\t\\mathbf{a}^{\\{1\\}} & =  \\mathbf{x}^{(i)} \\\\\n",
        "\t\t\t\t\\mathbf{z}^{\\{2\\}} & =  \\mathbf{W}^{\\{1\\}} \\cdot \\mathbf{a}^{\\{1\\}} + \\mathbf{b}^{\\{1\\}}\\\\\n",
        "\t\t\t\t\\mathbf{a}^{\\{2\\}} & =  \\sigma(\\mathbf{z}^{\\{2\\}}) \\\\\n",
        "\t\t\t\t\\mathbf{z}^{\\{3\\}} & =  \\mathbf{W}^{\\{2\\}} \\cdot \\mathbf{a}^{\\{2\\}}  + \\mathbf{b}^{\\{2\\}}\\\\\n",
        "\t\t\t\t\\mathbf{a}^{\\{3\\}} & =  \\sigma(\\mathbf{z}^{\\{3\\}})\\\\\n",
        "                \\mathbf{z}^{\\{4\\}} & =  \\mathbf{W}^{\\{3\\}} \\cdot \\mathbf{a}^{\\{3\\}}  + \\mathbf{b}^{\\{3\\}}\\\\\n",
        "\t\t\t\t\\mathbf{a}^{\\{4\\}} & =  \\sigma(\\mathbf{z}^{\\{4\\}})\\\\\n",
        "\t\t\t\t\\hat{y}^{(i)} & =  \\mathbf{a}^{\\{4\\}}\n",
        "\t\t\t\\end{split}\n",
        "      $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b81eec24",
      "metadata": {
        "id": "b81eec24"
      },
      "outputs": [],
      "source": [
        "def hacia_adelante(x, W1, b1, W2, b2, W3, b3):\n",
        "    z2 = np.dot(W1.T, x[:, np.newaxis]) + b1\n",
        "    a2 = sigmoide(z2)\n",
        "    z3 = np.dot(W2.T, a2) + b2\n",
        "    a3 = sigmoide(z3)\n",
        "    z4 = np.dot(W3.T, a3) + b3\n",
        "    y_hat = sigmoide(z4)\n",
        "    return z2, a2, z3, a3, z4, y_hat"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e83635b",
      "metadata": {
        "id": "7e83635b"
      },
      "source": [
        "FinalmSe define la función para entrenar nuestra red neuronal usando gradiente descendente. Para calcular el gradiente de la función de pérdida respecto a los pesos y sesgos en cada capa empleamos el algoritmo de retropropagación.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "cd03c463",
      "metadata": {
        "id": "cd03c463"
      },
      "outputs": [],
      "source": [
        "def retropropagacion(X, y, alpha = 0.01, n_epocas = 100, n_ocultas = 3):\n",
        "    n_ejemplos = X.shape[0]\n",
        "    n_entradas = X.shape[1]\n",
        "        \n",
        "    # Inicialización de las matrices de pesos W y V\n",
        "    W1 = np.sqrt(1.0 / n_entradas) * np.random.randn(n_entradas, n_ocultas)\n",
        "    b1 = np.zeros((n_ocultas, 1))\n",
        "    \n",
        "    W2 = np.sqrt(1.0 / n_entradas) * np.random.randn(n_ocultas, n_ocultas)\n",
        "    b2 = np.zeros((n_ocultas, 1))\n",
        "    \n",
        "    W3 = np.sqrt(1.0 / n_ocultas) * np.random.randn(n_ocultas, 1)\n",
        "    b3 = np.zeros((1, 1))\n",
        "    \n",
        "    perdidas = np.zeros((n_epocas))\n",
        "    exactitudes = np.zeros((n_epocas))\n",
        "    y_predicha = np.zeros((y.shape))\n",
        "    for i in range(n_epocas):\n",
        "        for j in range(n_ejemplos):\n",
        "            z2, a2, z3, a3, z4, y_hat = hacia_adelante(X[j], W1, b1, W2, b2, W3, b3)\n",
        "\n",
        "            # cálculo de gradientes para W3 y b3 por retropropagación\n",
        "            dz4 = y_hat - y[j]\n",
        "            dW3 = np.outer(a3, dz4) * derivada_sigmoide(z4)\n",
        "            db3 = dz4\n",
        "\n",
        "            # cálculo de gradientes para W2 y b2 por retropropagación\n",
        "            dz3 = np.dot(W3, dz4) * derivada_sigmoide(z3)\n",
        "            dW2 = np.outer(a2, dz3)\n",
        "            db2 = dz3\n",
        "            \n",
        "            # cálculo de gradientes para W1 y b1 por retropropagación\n",
        "            dz2 = np.dot(W2, dz3) * derivada_sigmoide(z2)\n",
        "            dW1 = np.outer(X[j], dz2)\n",
        "            db1 = dz2\n",
        "\n",
        "            # la actualización de los parámetros\n",
        "            # debe hacerse de forma simultánea\n",
        "            W3 = W3 - alpha * dW3\n",
        "            b3 = b3 - alpha * db3              \n",
        "            W2 = W2 - alpha * dW2\n",
        "            b2 = b2 - alpha * db2\n",
        "            W1 = W1 - alpha * dW1\n",
        "            b1 = b1 - alpha * db1\n",
        "\n",
        "            y_predicha[j] = y_hat\n",
        "            \n",
        "        # calcula la pérdida en la época\n",
        "        perdidas[i] = ECB(y, y_predicha)\n",
        "        exactitudes[i] = exactitud(y, np.round(y_predicha))\n",
        "        print('Epoch {0}: Pérdida = {1} Exactitud = {2}'.format(i, \n",
        "                                                              perdidas[i], \n",
        "                                                              exactitudes[i]))\n",
        "\n",
        "    return W1, W2, W3, perdidas, exactitudes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ac65ed4",
      "metadata": {
        "id": "4ac65ed4"
      },
      "source": [
        "## Prueba considerando la operación XOR."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c5755f5f",
      "metadata": {
        "id": "c5755f5f"
      },
      "outputs": [],
      "source": [
        "# ejemplo (XOR)\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([[0, 1, 1, 0]]).T"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59bce665",
      "metadata": {
        "id": "59bce665"
      },
      "source": [
        "Finalmente, entrenamos nuestra red con estos ejemplos por 50 épocas usando una tasa de aprendizaje $\\alpha = 2$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "140937ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "140937ec",
        "outputId": "1f7ab01a-8977-4d5c-f1e9-caa91350f89e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Pérdida = 4.780265814405273 Exactitud = 25.0\n",
            "Epoch 1: Pérdida = 4.443202515632271 Exactitud = 50.0\n",
            "Epoch 2: Pérdida = 4.376765668042093 Exactitud = 50.0\n",
            "Epoch 3: Pérdida = 4.324670862838479 Exactitud = 50.0\n",
            "Epoch 4: Pérdida = 4.280614153080169 Exactitud = 50.0\n",
            "Epoch 5: Pérdida = 4.24207793556266 Exactitud = 50.0\n",
            "Epoch 6: Pérdida = 4.206816320556837 Exactitud = 50.0\n",
            "Epoch 7: Pérdida = 4.173139764961292 Exactitud = 50.0\n",
            "Epoch 8: Pérdida = 4.140565944389521 Exactitud = 50.0\n",
            "Epoch 9: Pérdida = 4.110251098434749 Exactitud = 50.0\n",
            "Epoch 10: Pérdida = 4.084226040009762 Exactitud = 50.0\n",
            "Epoch 11: Pérdida = 4.063649308164782 Exactitud = 50.0\n",
            "Epoch 12: Pérdida = 4.048109145320366 Exactitud = 50.0\n",
            "Epoch 13: Pérdida = 4.036426215110716 Exactitud = 50.0\n",
            "Epoch 14: Pérdida = 4.0274754240134945 Exactitud = 50.0\n",
            "Epoch 15: Pérdida = 4.020436300558166 Exactitud = 50.0\n",
            "Epoch 16: Pérdida = 4.014757276844345 Exactitud = 50.0\n",
            "Epoch 17: Pérdida = 4.010071200970525 Exactitud = 50.0\n",
            "Epoch 18: Pérdida = 4.006129500982318 Exactitud = 50.0\n",
            "Epoch 19: Pérdida = 4.002759509600414 Exactitud = 50.0\n",
            "Epoch 20: Pérdida = 3.999837972102233 Exactitud = 50.0\n",
            "Epoch 21: Pérdida = 3.997274579282916 Exactitud = 50.0\n",
            "Epoch 22: Pérdida = 3.9950015506633267 Exactitud = 50.0\n",
            "Epoch 23: Pérdida = 3.9929668891124463 Exactitud = 50.0\n",
            "Epoch 24: Pérdida = 3.9911299026704903 Exactitud = 50.0\n",
            "Epoch 25: Pérdida = 3.9894581573957533 Exactitud = 50.0\n",
            "Epoch 26: Pérdida = 3.987925354324665 Exactitud = 50.0\n",
            "Epoch 27: Pérdida = 3.98650981654672 Exactitud = 50.0\n",
            "Epoch 28: Pérdida = 3.985193387409166 Exactitud = 50.0\n",
            "Epoch 29: Pérdida = 3.9839606108195884 Exactitud = 50.0\n",
            "Epoch 30: Pérdida = 3.9827981080338333 Exactitud = 50.0\n",
            "Epoch 31: Pérdida = 3.9816940927890867 Exactitud = 50.0\n",
            "Epoch 32: Pérdida = 3.9806379843205306 Exactitud = 50.0\n",
            "Epoch 33: Pérdida = 3.979620089324685 Exactitud = 50.0\n",
            "Epoch 34: Pérdida = 3.9786313314940154 Exactitud = 50.0\n",
            "Epoch 35: Pérdida = 3.9776630121833354 Exactitud = 50.0\n",
            "Epoch 36: Pérdida = 3.976706588902794 Exactitud = 50.0\n",
            "Epoch 37: Pérdida = 3.975753460172341 Exactitud = 50.0\n",
            "Epoch 38: Pérdida = 3.9747947461235094 Exactitud = 50.0\n",
            "Epoch 39: Pérdida = 3.9738210542674812 Exactitud = 50.0\n",
            "Epoch 40: Pérdida = 3.9728222191399203 Exactitud = 50.0\n",
            "Epoch 41: Pérdida = 3.971787003086225 Exactitud = 50.0\n",
            "Epoch 42: Pérdida = 3.9707027432054223 Exactitud = 50.0\n",
            "Epoch 43: Pérdida = 3.9695549263030974 Exactitud = 50.0\n",
            "Epoch 44: Pérdida = 3.9683266694168746 Exactitud = 50.0\n",
            "Epoch 45: Pérdida = 3.966998077782681 Exactitud = 50.0\n",
            "Epoch 46: Pérdida = 3.965545444589031 Exactitud = 50.0\n",
            "Epoch 47: Pérdida = 3.963940246921119 Exactitud = 50.0\n",
            "Epoch 48: Pérdida = 3.9621478790652045 Exactitud = 50.0\n",
            "Epoch 49: Pérdida = 3.9601260465901076 Exactitud = 50.0\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(0)\n",
        "W1, W2, W3, perdidas, exactitudes = retropropagacion(X, \n",
        "                                                 y, \n",
        "                                                 alpha = 2, \n",
        "                                                 n_epocas = 50,\n",
        "                                                 n_ocultas = 5)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}